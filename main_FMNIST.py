# -*- coding: utf-8 -*-
"""main_FMNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a7Zk0aXn60_Bpt7b6sNTKR6BBor7aZtM
"""

#imports
import argparse
import tensorflow as tf
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.utils.multiclass import unique_labels
from util_FMNIST import load_data, preprocess_data
from model_FMNIST import fmnist_model1, fmnist_model2

#load data:
train_data, val_data, test_data, num_classes = load_data()

#preprocess data:
train_data = train_data.map(preprocess_data).shuffle(10000).batch(128)
val_data = val_data.map(preprocess_data).batch(128)
test_data = test_data.map(preprocess_data).batch(128)

# Create models for 2 different architectures each with and without regularizer

#model:Tyler
models1 = [
    fmnist_model1(num_classes, use_regularizer=False),
    fmnist_model1(num_classes, use_regularizer=True)
]

#model : Jackson
models2 = [
    fmnist_model2(num_classes, use_regularizer=False),
    fmnist_model2(num_classes, use_regularizer=True)
]

histories = []

#Compile and train the first model: Tyler
for i, model in enumerate(models1):
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])
    # Train model and save history
    history = model.fit(train_data, epochs=100, validation_data=val_data)
    histories.append(history)

    # Evaluate model on test data
    loss, accuracy = model.evaluate(test_data)
    print(f"Model {i} - Test loss: {loss}, Test accuracy: {accuracy}")
    
    # Save the trained model
    model.save(f"model_Tyler_{i}.h5")

# Load the test data
test_data = tfds.load('fashion_mnist', split='test', as_supervised=True)

# Load the trained model
model = tf.keras.models.load_model('model_Tyler_1.h5')

# Get the class names
class_names = np.array(['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
                        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])

# Make predictions on the test data
test_predictions = []
test_labels = []
for image, label in test_data:
    test_predictions.append(np.argmax(model.predict(np.expand_dims(image, axis=0))))
    test_labels.append(label.numpy())
    
    
# Compute the confusion matrix
cm = confusion_matrix(test_labels, test_predictions)

# Normalize the confusion matrix
cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


# Plot the confusion matrix as a heatmap
fig, ax = plt.subplots(figsize=(9, 9))
im = ax.imshow(cm, cmap=plt.cm.YlGn)

# Add axis labels and a color bar
ax.set_xticks(np.arange(len(class_names)))
ax.set_yticks(np.arange(len(class_names)))
ax.set_xticklabels(class_names)
ax.set_yticklabels(class_names)
ax.set_xlabel('Predicted label')
ax.set_ylabel('True label')
fig.colorbar(im)

# Add the values of the confusion matrix to each cell
thresh = cm.max() / 2.
for i in range(len(class_names)):
    for j in range(len(class_names)):
        ax.text(j, i, '{:.2f}'.format(cm[i, j]),
                ha='center', va='center',
                color='white' if cm[i, j] > thresh else 'black')

# Show the plot

plt.show()

#plot training and validation accuracy and losses for Tyler:
for i, history in enumerate(histories):
    
    plt.subplot(2, 2, i*2+1)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model {} Loss'.format(i))
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Val'], loc='upper right')
    
    plt.subplot(2, 2, i*2+2)
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model {} Accuracy'.format(i))
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Val'], loc='lower right')
    
plt.tight_layout()
plt.show()

histories2 = []


#Compile and train the second model: Jackson
for i, model2 in enumerate(models2):
    model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])
    # Train model and save history
    history2 = model2.fit(train_data, epochs=50, validation_data=val_data)
    histories2.append(history2)

    # Evaluate model on test data
    loss, accuracy = model2.evaluate(test_data)
    print(f"Model {i} - Test loss: {loss}, Test accuracy: {accuracy}")
    
    # Save the trained model
    model2.save(f"model_Jackson_{i}.h5")

# Load the test data
test_data = tfds.load('fashion_mnist', split='test', as_supervised=True)

# Load the trained model
model = tf.keras.models.load_model('model_Jackson_1.h5')

# Get the class names
class_names = np.array(['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
                        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])

# Make predictions on the test data
test_predictions = []
test_labels = []
for image, label in test_data:
    test_predictions.append(np.argmax(model.predict(np.expand_dims(image, axis=0))))
    test_labels.append(label.numpy())
    
    
# Compute the confusion matrix
cm = confusion_matrix(test_labels, test_predictions)

# Normalize the confusion matrix
cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


# Plot the confusion matrix as a heatmap
fig, ax = plt.subplots(figsize=(9, 9))
im = ax.imshow(cm, cmap=plt.cm.OrRd)

# Add axis labels and a color bar
ax.set_xticks(np.arange(len(class_names)))
ax.set_yticks(np.arange(len(class_names)))
ax.set_xticklabels(class_names)
ax.set_yticklabels(class_names)
ax.set_xlabel('Predicted label')
ax.set_ylabel('True label')
fig.colorbar(im)

# Add the values of the confusion matrix to each cell
thresh = cm.max() / 2.
for i in range(len(class_names)):
    for j in range(len(class_names)):
        ax.text(j, i, '{:.2f}'.format(cm[i, j]),
                ha='center', va='center',
                color='white' if cm[i, j] > thresh else 'black')

# Show the plot

plt.show()

#plot training and validation accuracy and losses for Jackson:
for i, history in enumerate(histories2):
    
    plt.subplot(2, 2, i*2+1)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model {} Loss'.format(i))
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Val'], loc='upper right')
    
    plt.subplot(2, 2, i*2+2)
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model {} Accuracy'.format(i))
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Val'], loc='lower right')
    
plt.tight_layout()
plt.show()

